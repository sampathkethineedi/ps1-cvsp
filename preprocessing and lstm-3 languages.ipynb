{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model for three langauages\n",
    "This part contains the attempts I made for LSTMs in three languages. The data set is the same one I used for 5, but I removed two languages from the csv sheet I had saved everything in and left only 3. I tried various different models, each having different levels of effectiveness, the details of which I will denote later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import librosa\n",
    "import os\n",
    "import csv\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow_core.keras import Model\n",
    "from tensorflow_core.python.keras.layers import Input, Dense, GRU, LSTM, Dropout, Bidirectional\n",
    "from tensorflow_core.keras import optimizers\n",
    "from tensorflow_core.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code snippets is to read the datasets thst we have and remove the first filename column so that it becomes a proper array we can use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>seq1</th>\n",
       "      <th>seq2</th>\n",
       "      <th>seq3</th>\n",
       "      <th>seq4</th>\n",
       "      <th>seq5</th>\n",
       "      <th>seq6</th>\n",
       "      <th>seq7</th>\n",
       "      <th>seq8</th>\n",
       "      <th>seq9</th>\n",
       "      <th>...</th>\n",
       "      <th>seq79</th>\n",
       "      <th>seq80</th>\n",
       "      <th>seq81</th>\n",
       "      <th>seq82</th>\n",
       "      <th>seq83</th>\n",
       "      <th>seq84</th>\n",
       "      <th>seq85</th>\n",
       "      <th>seq86</th>\n",
       "      <th>seq87</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>common_voice_tr_17341269.mp3</td>\n",
       "      <td>-28.671259</td>\n",
       "      <td>-28.671259</td>\n",
       "      <td>-28.671259</td>\n",
       "      <td>-28.594355</td>\n",
       "      <td>-23.302088</td>\n",
       "      <td>-21.683058</td>\n",
       "      <td>-22.529316</td>\n",
       "      <td>-20.512342</td>\n",
       "      <td>-19.944502</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.218327</td>\n",
       "      <td>-7.162225</td>\n",
       "      <td>-7.152306</td>\n",
       "      <td>-7.921572</td>\n",
       "      <td>-8.872492</td>\n",
       "      <td>-10.029106</td>\n",
       "      <td>-8.932535</td>\n",
       "      <td>-8.830759</td>\n",
       "      <td>-8.814616</td>\n",
       "      <td>Turkish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>common_voice_tr_17341270.mp3</td>\n",
       "      <td>-18.675406</td>\n",
       "      <td>-12.775420</td>\n",
       "      <td>-10.191453</td>\n",
       "      <td>-9.995229</td>\n",
       "      <td>-9.822378</td>\n",
       "      <td>-10.787068</td>\n",
       "      <td>-11.464541</td>\n",
       "      <td>-11.791995</td>\n",
       "      <td>-12.880933</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.941443</td>\n",
       "      <td>-5.437989</td>\n",
       "      <td>-4.313529</td>\n",
       "      <td>-3.594510</td>\n",
       "      <td>-4.578447</td>\n",
       "      <td>-4.841236</td>\n",
       "      <td>-6.277249</td>\n",
       "      <td>-7.314360</td>\n",
       "      <td>-6.984949</td>\n",
       "      <td>Turkish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>common_voice_tr_17341271.mp3</td>\n",
       "      <td>-29.168598</td>\n",
       "      <td>-28.445410</td>\n",
       "      <td>-25.697535</td>\n",
       "      <td>-21.021667</td>\n",
       "      <td>-18.727261</td>\n",
       "      <td>-19.127209</td>\n",
       "      <td>-20.424198</td>\n",
       "      <td>-18.682182</td>\n",
       "      <td>-16.259388</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.501460</td>\n",
       "      <td>-4.253098</td>\n",
       "      <td>-3.483280</td>\n",
       "      <td>-3.627386</td>\n",
       "      <td>-5.621589</td>\n",
       "      <td>-7.772541</td>\n",
       "      <td>-10.608480</td>\n",
       "      <td>-10.832165</td>\n",
       "      <td>-9.111898</td>\n",
       "      <td>Turkish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>common_voice_tr_17341278.mp3</td>\n",
       "      <td>-35.198715</td>\n",
       "      <td>-35.198715</td>\n",
       "      <td>-35.198715</td>\n",
       "      <td>-35.198715</td>\n",
       "      <td>-35.198715</td>\n",
       "      <td>-35.198715</td>\n",
       "      <td>-35.198715</td>\n",
       "      <td>-34.657932</td>\n",
       "      <td>-32.157036</td>\n",
       "      <td>...</td>\n",
       "      <td>-35.465096</td>\n",
       "      <td>-34.565926</td>\n",
       "      <td>-34.064175</td>\n",
       "      <td>-25.434107</td>\n",
       "      <td>-18.991602</td>\n",
       "      <td>-16.503279</td>\n",
       "      <td>-16.020468</td>\n",
       "      <td>-17.432213</td>\n",
       "      <td>-17.578808</td>\n",
       "      <td>Turkish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>common_voice_tr_17341279.mp3</td>\n",
       "      <td>-32.834057</td>\n",
       "      <td>-32.834057</td>\n",
       "      <td>-32.834057</td>\n",
       "      <td>-32.834057</td>\n",
       "      <td>-32.834057</td>\n",
       "      <td>-32.834057</td>\n",
       "      <td>-32.834057</td>\n",
       "      <td>-32.834057</td>\n",
       "      <td>-32.834057</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.736340</td>\n",
       "      <td>-19.915949</td>\n",
       "      <td>-13.989322</td>\n",
       "      <td>-12.898703</td>\n",
       "      <td>-16.812244</td>\n",
       "      <td>-17.894398</td>\n",
       "      <td>-15.678299</td>\n",
       "      <td>-14.883287</td>\n",
       "      <td>-15.698987</td>\n",
       "      <td>Turkish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       filename       seq1       seq2       seq3       seq4  \\\n",
       "0  common_voice_tr_17341269.mp3 -28.671259 -28.671259 -28.671259 -28.594355   \n",
       "1  common_voice_tr_17341270.mp3 -18.675406 -12.775420 -10.191453  -9.995229   \n",
       "2  common_voice_tr_17341271.mp3 -29.168598 -28.445410 -25.697535 -21.021667   \n",
       "3  common_voice_tr_17341278.mp3 -35.198715 -35.198715 -35.198715 -35.198715   \n",
       "4  common_voice_tr_17341279.mp3 -32.834057 -32.834057 -32.834057 -32.834057   \n",
       "\n",
       "        seq5       seq6       seq7       seq8       seq9  ...      seq79  \\\n",
       "0 -23.302088 -21.683058 -22.529316 -20.512342 -19.944502  ...  -8.218327   \n",
       "1  -9.822378 -10.787068 -11.464541 -11.791995 -12.880933  ...  -5.941443   \n",
       "2 -18.727261 -19.127209 -20.424198 -18.682182 -16.259388  ...  -6.501460   \n",
       "3 -35.198715 -35.198715 -35.198715 -34.657932 -32.157036  ... -35.465096   \n",
       "4 -32.834057 -32.834057 -32.834057 -32.834057 -32.834057  ... -21.736340   \n",
       "\n",
       "       seq80      seq81      seq82      seq83      seq84      seq85  \\\n",
       "0  -7.162225  -7.152306  -7.921572  -8.872492 -10.029106  -8.932535   \n",
       "1  -5.437989  -4.313529  -3.594510  -4.578447  -4.841236  -6.277249   \n",
       "2  -4.253098  -3.483280  -3.627386  -5.621589  -7.772541 -10.608480   \n",
       "3 -34.565926 -34.064175 -25.434107 -18.991602 -16.503279 -16.020468   \n",
       "4 -19.915949 -13.989322 -12.898703 -16.812244 -17.894398 -15.678299   \n",
       "\n",
       "       seq86      seq87    label  \n",
       "0  -8.830759  -8.814616  Turkish  \n",
       "1  -7.314360  -6.984949  Turkish  \n",
       "2 -10.832165  -9.111898  Turkish  \n",
       "3 -17.432213 -17.578808  Turkish  \n",
       "4 -14.883287 -15.698987  Turkish  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('NEWts3lang.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dropping unneccesary columns\n",
    "data = data.drop(['filename'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq1</th>\n",
       "      <th>seq2</th>\n",
       "      <th>seq3</th>\n",
       "      <th>seq4</th>\n",
       "      <th>seq5</th>\n",
       "      <th>seq6</th>\n",
       "      <th>seq7</th>\n",
       "      <th>seq8</th>\n",
       "      <th>seq9</th>\n",
       "      <th>seq10</th>\n",
       "      <th>...</th>\n",
       "      <th>seq79</th>\n",
       "      <th>seq80</th>\n",
       "      <th>seq81</th>\n",
       "      <th>seq82</th>\n",
       "      <th>seq83</th>\n",
       "      <th>seq84</th>\n",
       "      <th>seq85</th>\n",
       "      <th>seq86</th>\n",
       "      <th>seq87</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-28.671259</td>\n",
       "      <td>-28.671259</td>\n",
       "      <td>-28.671259</td>\n",
       "      <td>-28.594355</td>\n",
       "      <td>-23.302088</td>\n",
       "      <td>-21.683058</td>\n",
       "      <td>-22.529316</td>\n",
       "      <td>-20.512342</td>\n",
       "      <td>-19.944502</td>\n",
       "      <td>-19.473763</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.218327</td>\n",
       "      <td>-7.162225</td>\n",
       "      <td>-7.152306</td>\n",
       "      <td>-7.921572</td>\n",
       "      <td>-8.872492</td>\n",
       "      <td>-10.029106</td>\n",
       "      <td>-8.932535</td>\n",
       "      <td>-8.830759</td>\n",
       "      <td>-8.814616</td>\n",
       "      <td>Turkish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-18.675406</td>\n",
       "      <td>-12.775420</td>\n",
       "      <td>-10.191453</td>\n",
       "      <td>-9.995229</td>\n",
       "      <td>-9.822378</td>\n",
       "      <td>-10.787068</td>\n",
       "      <td>-11.464541</td>\n",
       "      <td>-11.791995</td>\n",
       "      <td>-12.880933</td>\n",
       "      <td>-12.484132</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.941443</td>\n",
       "      <td>-5.437989</td>\n",
       "      <td>-4.313529</td>\n",
       "      <td>-3.594510</td>\n",
       "      <td>-4.578447</td>\n",
       "      <td>-4.841236</td>\n",
       "      <td>-6.277249</td>\n",
       "      <td>-7.314360</td>\n",
       "      <td>-6.984949</td>\n",
       "      <td>Turkish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-29.168598</td>\n",
       "      <td>-28.445410</td>\n",
       "      <td>-25.697535</td>\n",
       "      <td>-21.021667</td>\n",
       "      <td>-18.727261</td>\n",
       "      <td>-19.127209</td>\n",
       "      <td>-20.424198</td>\n",
       "      <td>-18.682182</td>\n",
       "      <td>-16.259388</td>\n",
       "      <td>-15.557657</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.501460</td>\n",
       "      <td>-4.253098</td>\n",
       "      <td>-3.483280</td>\n",
       "      <td>-3.627386</td>\n",
       "      <td>-5.621589</td>\n",
       "      <td>-7.772541</td>\n",
       "      <td>-10.608480</td>\n",
       "      <td>-10.832165</td>\n",
       "      <td>-9.111898</td>\n",
       "      <td>Turkish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-35.198715</td>\n",
       "      <td>-35.198715</td>\n",
       "      <td>-35.198715</td>\n",
       "      <td>-35.198715</td>\n",
       "      <td>-35.198715</td>\n",
       "      <td>-35.198715</td>\n",
       "      <td>-35.198715</td>\n",
       "      <td>-34.657932</td>\n",
       "      <td>-32.157036</td>\n",
       "      <td>-28.223465</td>\n",
       "      <td>...</td>\n",
       "      <td>-35.465096</td>\n",
       "      <td>-34.565926</td>\n",
       "      <td>-34.064175</td>\n",
       "      <td>-25.434107</td>\n",
       "      <td>-18.991602</td>\n",
       "      <td>-16.503279</td>\n",
       "      <td>-16.020468</td>\n",
       "      <td>-17.432213</td>\n",
       "      <td>-17.578808</td>\n",
       "      <td>Turkish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-32.834057</td>\n",
       "      <td>-32.834057</td>\n",
       "      <td>-32.834057</td>\n",
       "      <td>-32.834057</td>\n",
       "      <td>-32.834057</td>\n",
       "      <td>-32.834057</td>\n",
       "      <td>-32.834057</td>\n",
       "      <td>-32.834057</td>\n",
       "      <td>-32.834057</td>\n",
       "      <td>-32.834057</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.736340</td>\n",
       "      <td>-19.915949</td>\n",
       "      <td>-13.989322</td>\n",
       "      <td>-12.898703</td>\n",
       "      <td>-16.812244</td>\n",
       "      <td>-17.894398</td>\n",
       "      <td>-15.678299</td>\n",
       "      <td>-14.883287</td>\n",
       "      <td>-15.698987</td>\n",
       "      <td>Turkish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        seq1       seq2       seq3       seq4       seq5       seq6  \\\n",
       "0 -28.671259 -28.671259 -28.671259 -28.594355 -23.302088 -21.683058   \n",
       "1 -18.675406 -12.775420 -10.191453  -9.995229  -9.822378 -10.787068   \n",
       "2 -29.168598 -28.445410 -25.697535 -21.021667 -18.727261 -19.127209   \n",
       "3 -35.198715 -35.198715 -35.198715 -35.198715 -35.198715 -35.198715   \n",
       "4 -32.834057 -32.834057 -32.834057 -32.834057 -32.834057 -32.834057   \n",
       "\n",
       "        seq7       seq8       seq9      seq10  ...      seq79      seq80  \\\n",
       "0 -22.529316 -20.512342 -19.944502 -19.473763  ...  -8.218327  -7.162225   \n",
       "1 -11.464541 -11.791995 -12.880933 -12.484132  ...  -5.941443  -5.437989   \n",
       "2 -20.424198 -18.682182 -16.259388 -15.557657  ...  -6.501460  -4.253098   \n",
       "3 -35.198715 -34.657932 -32.157036 -28.223465  ... -35.465096 -34.565926   \n",
       "4 -32.834057 -32.834057 -32.834057 -32.834057  ... -21.736340 -19.915949   \n",
       "\n",
       "       seq81      seq82      seq83      seq84      seq85      seq86  \\\n",
       "0  -7.152306  -7.921572  -8.872492 -10.029106  -8.932535  -8.830759   \n",
       "1  -4.313529  -3.594510  -4.578447  -4.841236  -6.277249  -7.314360   \n",
       "2  -3.483280  -3.627386  -5.621589  -7.772541 -10.608480 -10.832165   \n",
       "3 -34.064175 -25.434107 -18.991602 -16.503279 -16.020468 -17.432213   \n",
       "4 -13.989322 -12.898703 -16.812244 -17.894398 -15.678299 -14.883287   \n",
       "\n",
       "       seq87    label  \n",
       "0  -8.814616  Turkish  \n",
       "1  -6.984949  Turkish  \n",
       "2  -9.111898  Turkish  \n",
       "3 -17.578808  Turkish  \n",
       "4 -15.698987  Turkish  \n",
       "\n",
       "[5 rows x 88 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code is to encode the labels into numbers, where each language is represented by a number for the classification algorithm to begin working on it. The encoder encodes the langauges in alphabetical order.\n",
    "After this, the labels are converted into a form that uses a categorical crossentropy loss function, where each sample of the labels have three data points, and 0 if it is not the language, and 1 if it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Turkish\n",
       "1       Turkish\n",
       "2       Turkish\n",
       "3       Turkish\n",
       "4       Turkish\n",
       "         ...   \n",
       "8995    Swedish\n",
       "8996    Swedish\n",
       "8997    Swedish\n",
       "8998    Swedish\n",
       "8999    Swedish\n",
       "Name: label, Length: 9000, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_list = data.iloc[:, -1]\n",
    "language_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(language_list)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_Y = encoder.transform(y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code scales the data in X and then separates it into train and test data along with the labels. A ratio of 0.2 is used for this purpose, as it is the common ratio used for train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, dummy_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was to reshape the data to be able to pass it through the LSTM. The first number should contain the number of samples that were going to be passed through, the second one should be the number of time stamps taken, and the third one is 1 to reflect one feature that has 87 timestamps for each MFCC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(7200,87,1)\n",
    "X_test = X_test.reshape(1800,87,1)\n",
    "y_train = y_train.reshape(7200,3)\n",
    "y_test = y_test.reshape(1800,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the model.\n",
    "The final model with the parameters obtained is given below, which gave around 77% accuracy on three languages on the test data that was used. Some details of other models that I tried will be explained.\n",
    "\n",
    "## Attempt 1:With mean of MFCCs\n",
    "This was the attempt I did with the wrong shape of data; however it seemed to have a high accuracy even for the test data. On further test data, it failed.\n",
    "\n",
    "| LSTM layers | Dense layers | Dropout values | Accuracy | Test Accuracy |\n",
    "| :- | :- | :- | :- | :- |\n",
    "| Two LSTM layers, 20 and 10 units each | Two Dense layers, 100 units and final layer with 3 units | 0.2 | 0.82 | 0.79(but only 0.32 on further test data) |\n",
    "\n",
    "## Attempt 2:With data size 50; taken in parts from samples\n",
    "This was with proper data but might not have taken enough samples.\n",
    "(wherever not mentioned, tanh activation is used)\n",
    "\n",
    "| LSTM layers | Dense layers | Dropout values | Accuracy | Test Accuracy |\n",
    "| :- | :- | :- | :- | :- |\n",
    "| One bidirectional layer, 100 units | Two Dense layers, 100 units and final layer with 3 units | 0.3 | 0.75 | 0.66 |\n",
    "| One bidirectional layer, 50 units, | Two Dense layers, 100 units and final layer with 3 units | 0.3 | 0.69 | 0.66 |\n",
    "| One bidirectional layer, 50 units, One bidirectional layer, 25 units | Two Dense layers, 100 units(relu) and final layer with 3 units | 0.3 | 0.73 | 0.7 |\n",
    "| One bidirectional layer, 50 units, One bidirectional layer, 25 units | Two Dense layers, 200 units and final layer with 3 units | 0.3 | 0.72 | 0.69 |\n",
    "\n",
    "At this point I decided to try with the other data set, as I thought maybe the samples were too short and/or there weren't enough audio files sampled.\n",
    "\n",
    "## Attempt 3:with data size 87; taken in parts from samples\n",
    "\n",
    "| LSTM layers | Dense layers | Dropout values | Accuracy | Test Accuracy |\n",
    "| :- | :- | :- | :- | :- |\n",
    "| One bidirectional layer, 87 units, One bidirectional layer, 43 units | Two Dense layers, 100(relu) units and final layer with 3 units | 0.3 | 0.77 | 0.73 |\n",
    "| One bidirectional layer, 87 units, One bidirectional layer, 43 units | Two Dense layers, 100(relu) units and final layer with 3 units | 0.4 | 0.79 | 0.76 |\n",
    "| One bidirectional layer, 87 units, One bidirectional layer, 43 units | Two Dense layers, 100(relu) units and final layer with 3 units | 0.4 (rec dropout=0.2)| 0.77 | 0.78 |\n",
    "\n",
    "These are all the various different models attempted with their results compiled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Compiling model...\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "main_input (InputLayer)      [(None, 87, 1)]           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_16 (Bidirectio (None, 87, 174)           61944     \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 87, 174)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_17 (Bidirectio (None, 86)                74992     \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 86)                0         \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (None, 100)               8700      \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "rnn_output (Dense)           (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 145,939\n",
      "Trainable params: 145,939\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 7200 samples, validate on 1800 samples\n",
      "Epoch 1/70\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000236D38F7E58> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000236D38F7E58> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n",
      "7200/7200 [==============================] - 206s 29ms/sample - loss: 0.9898 - acc: 0.5142 - val_loss: 0.9107 - val_acc: 0.5672\n",
      "Epoch 2/70\n",
      "7200/7200 [==============================] - 183s 25ms/sample - loss: 0.9230 - acc: 0.5668 - val_loss: 0.8499 - val_acc: 0.6133\n",
      "Epoch 3/70\n",
      "7200/7200 [==============================] - 183s 25ms/sample - loss: 0.8787 - acc: 0.5913 - val_loss: 0.8515 - val_acc: 0.5872\n",
      "Epoch 4/70\n",
      "7200/7200 [==============================] - 181s 25ms/sample - loss: 0.8460 - acc: 0.6096 - val_loss: 0.7918 - val_acc: 0.6556\n",
      "Epoch 5/70\n",
      "7200/7200 [==============================] - 182s 25ms/sample - loss: 0.8286 - acc: 0.6218 - val_loss: 0.7666 - val_acc: 0.6567\n",
      "Epoch 6/70\n",
      "7200/7200 [==============================] - 178s 25ms/sample - loss: 0.8197 - acc: 0.6235 - val_loss: 0.7541 - val_acc: 0.6656\n",
      "Epoch 7/70\n",
      "7200/7200 [==============================] - 179s 25ms/sample - loss: 0.8088 - acc: 0.6297 - val_loss: 0.7454 - val_acc: 0.6728\n",
      "Epoch 8/70\n",
      "7200/7200 [==============================] - 180s 25ms/sample - loss: 0.7916 - acc: 0.6422 - val_loss: 0.7183 - val_acc: 0.6844\n",
      "Epoch 9/70\n",
      "7200/7200 [==============================] - 182s 25ms/sample - loss: 0.7867 - acc: 0.6403 - val_loss: 0.7206 - val_acc: 0.6933\n",
      "Epoch 10/70\n",
      "7200/7200 [==============================] - 175s 24ms/sample - loss: 0.7769 - acc: 0.6510 - val_loss: 0.7188 - val_acc: 0.6789\n",
      "Epoch 11/70\n",
      "7200/7200 [==============================] - 181s 25ms/sample - loss: 0.7698 - acc: 0.6519 - val_loss: 0.7089 - val_acc: 0.7067\n",
      "Epoch 12/70\n",
      "7200/7200 [==============================] - 181s 25ms/sample - loss: 0.7587 - acc: 0.6668 - val_loss: 0.7309 - val_acc: 0.6822\n",
      "Epoch 13/70\n",
      "7200/7200 [==============================] - 174s 24ms/sample - loss: 0.7490 - acc: 0.6707 - val_loss: 0.6819 - val_acc: 0.7139\n",
      "Epoch 14/70\n",
      "7200/7200 [==============================] - 171s 24ms/sample - loss: 0.7439 - acc: 0.6689 - val_loss: 0.6810 - val_acc: 0.7161\n",
      "Epoch 15/70\n",
      "7200/7200 [==============================] - 182s 25ms/sample - loss: 0.7413 - acc: 0.6762 - val_loss: 0.6831 - val_acc: 0.6989\n",
      "Epoch 16/70\n",
      "7200/7200 [==============================] - 181s 25ms/sample - loss: 0.7322 - acc: 0.6714 - val_loss: 0.6862 - val_acc: 0.7094\n",
      "Epoch 17/70\n",
      "7200/7200 [==============================] - 189s 26ms/sample - loss: 0.7263 - acc: 0.6807 - val_loss: 0.6639 - val_acc: 0.7167\n",
      "Epoch 18/70\n",
      "7200/7200 [==============================] - 171s 24ms/sample - loss: 0.7210 - acc: 0.6786 - val_loss: 0.6589 - val_acc: 0.7172\n",
      "Epoch 19/70\n",
      "7200/7200 [==============================] - 178s 25ms/sample - loss: 0.7126 - acc: 0.6839 - val_loss: 0.6612 - val_acc: 0.7167\n",
      "Epoch 20/70\n",
      "7200/7200 [==============================] - 183s 25ms/sample - loss: 0.7020 - acc: 0.6894 - val_loss: 0.6433 - val_acc: 0.7328\n",
      "Epoch 21/70\n",
      "7200/7200 [==============================] - 210s 29ms/sample - loss: 0.6981 - acc: 0.6950 - val_loss: 0.6438 - val_acc: 0.7294\n",
      "Epoch 22/70\n",
      "7200/7200 [==============================] - 209s 29ms/sample - loss: 0.7005 - acc: 0.6985 - val_loss: 0.6282 - val_acc: 0.7361\n",
      "Epoch 23/70\n",
      "7200/7200 [==============================] - 213s 30ms/sample - loss: 0.6970 - acc: 0.7024 - val_loss: 0.6313 - val_acc: 0.7350\n",
      "Epoch 24/70\n",
      "7200/7200 [==============================] - 196s 27ms/sample - loss: 0.6898 - acc: 0.6967 - val_loss: 0.6273 - val_acc: 0.7433\n",
      "Epoch 25/70\n",
      "7200/7200 [==============================] - 199s 28ms/sample - loss: 0.6813 - acc: 0.7018 - val_loss: 0.6387 - val_acc: 0.7322\n",
      "Epoch 26/70\n",
      "7200/7200 [==============================] - 202s 28ms/sample - loss: 0.6869 - acc: 0.7063 - val_loss: 0.6216 - val_acc: 0.7394\n",
      "Epoch 27/70\n",
      "7200/7200 [==============================] - 196s 27ms/sample - loss: 0.6742 - acc: 0.7132 - val_loss: 0.6214 - val_acc: 0.7311\n",
      "Epoch 28/70\n",
      "7200/7200 [==============================] - 198s 27ms/sample - loss: 0.6745 - acc: 0.7150 - val_loss: 0.6104 - val_acc: 0.7450\n",
      "Epoch 29/70\n",
      "7200/7200 [==============================] - 205s 29ms/sample - loss: 0.6626 - acc: 0.7093 - val_loss: 0.5971 - val_acc: 0.7556\n",
      "Epoch 30/70\n",
      "7200/7200 [==============================] - 216s 30ms/sample - loss: 0.6645 - acc: 0.7147 - val_loss: 0.6058 - val_acc: 0.7483\n",
      "Epoch 31/70\n",
      "7200/7200 [==============================] - 210s 29ms/sample - loss: 0.6585 - acc: 0.7207 - val_loss: 0.6000 - val_acc: 0.7517\n",
      "Epoch 32/70\n",
      "7200/7200 [==============================] - 207s 29ms/sample - loss: 0.6517 - acc: 0.7219 - val_loss: 0.5940 - val_acc: 0.7561\n",
      "Epoch 33/70\n",
      "7200/7200 [==============================] - 198s 27ms/sample - loss: 0.6610 - acc: 0.7125 - val_loss: 0.5985 - val_acc: 0.7533\n",
      "Epoch 34/70\n",
      "7200/7200 [==============================] - 201s 28ms/sample - loss: 0.6485 - acc: 0.7239 - val_loss: 0.5959 - val_acc: 0.7544\n",
      "Epoch 35/70\n",
      "7200/7200 [==============================] - 202s 28ms/sample - loss: 0.6483 - acc: 0.7250 - val_loss: 0.5928 - val_acc: 0.7489\n",
      "Epoch 36/70\n",
      "7200/7200 [==============================] - 207s 29ms/sample - loss: 0.6487 - acc: 0.7239 - val_loss: 0.5970 - val_acc: 0.7500\n",
      "Epoch 37/70\n",
      "7200/7200 [==============================] - 223s 31ms/sample - loss: 0.6392 - acc: 0.7336 - val_loss: 0.6141 - val_acc: 0.7411\n",
      "Epoch 38/70\n",
      "7200/7200 [==============================] - 218s 30ms/sample - loss: 0.6398 - acc: 0.7312 - val_loss: 0.5853 - val_acc: 0.7572\n",
      "Epoch 39/70\n",
      "7200/7200 [==============================] - 202s 28ms/sample - loss: 0.6357 - acc: 0.7283 - val_loss: 0.5827 - val_acc: 0.7561\n",
      "Epoch 40/70\n",
      "7200/7200 [==============================] - 198s 27ms/sample - loss: 0.6346 - acc: 0.7285 - val_loss: 0.5800 - val_acc: 0.7644\n",
      "Epoch 41/70\n",
      "7200/7200 [==============================] - 196s 27ms/sample - loss: 0.6272 - acc: 0.7337 - val_loss: 0.5842 - val_acc: 0.7572\n",
      "Epoch 42/70\n",
      "7200/7200 [==============================] - 183s 25ms/sample - loss: 0.6253 - acc: 0.7361 - val_loss: 0.5662 - val_acc: 0.7700\n",
      "Epoch 43/70\n",
      "7200/7200 [==============================] - 191s 27ms/sample - loss: 0.6179 - acc: 0.7387 - val_loss: 0.5800 - val_acc: 0.7583\n",
      "Epoch 44/70\n",
      "7200/7200 [==============================] - 190s 26ms/sample - loss: 0.6235 - acc: 0.7428 - val_loss: 0.5735 - val_acc: 0.7667\n",
      "Epoch 45/70\n",
      "7200/7200 [==============================] - 199s 28ms/sample - loss: 0.6113 - acc: 0.7415 - val_loss: 0.5741 - val_acc: 0.7594\n",
      "Epoch 46/70\n",
      "7200/7200 [==============================] - 187s 26ms/sample - loss: 0.6193 - acc: 0.7378 - val_loss: 0.5686 - val_acc: 0.7667\n",
      "Epoch 47/70\n",
      "7200/7200 [==============================] - 197s 27ms/sample - loss: 0.6170 - acc: 0.7439 - val_loss: 0.5785 - val_acc: 0.7694\n",
      "Epoch 48/70\n",
      "7200/7200 [==============================] - 202s 28ms/sample - loss: 0.6140 - acc: 0.7481 - val_loss: 0.5649 - val_acc: 0.7694\n",
      "Epoch 49/70\n",
      "7200/7200 [==============================] - 185s 26ms/sample - loss: 0.6126 - acc: 0.7436 - val_loss: 0.5673 - val_acc: 0.7717\n",
      "Epoch 50/70\n",
      "7200/7200 [==============================] - 181s 25ms/sample - loss: 0.6047 - acc: 0.7460 - val_loss: 0.5737 - val_acc: 0.7650\n",
      "Epoch 51/70\n",
      "7200/7200 [==============================] - 192s 27ms/sample - loss: 0.6054 - acc: 0.7465 - val_loss: 0.5795 - val_acc: 0.7678\n",
      "Epoch 52/70\n",
      "7200/7200 [==============================] - 203s 28ms/sample - loss: 0.6046 - acc: 0.7469 - val_loss: 0.5694 - val_acc: 0.7728\n",
      "Epoch 53/70\n",
      "7200/7200 [==============================] - 195s 27ms/sample - loss: 0.6028 - acc: 0.7468 - val_loss: 0.5641 - val_acc: 0.7678\n",
      "Epoch 54/70\n",
      "7200/7200 [==============================] - 195s 27ms/sample - loss: 0.5868 - acc: 0.7551 - val_loss: 0.5662 - val_acc: 0.7711\n",
      "Epoch 55/70\n",
      "7200/7200 [==============================] - 194s 27ms/sample - loss: 0.5920 - acc: 0.7525 - val_loss: 0.5659 - val_acc: 0.7700\n",
      "Epoch 56/70\n",
      "7200/7200 [==============================] - 206s 29ms/sample - loss: 0.5997 - acc: 0.7496 - val_loss: 0.5574 - val_acc: 0.7817\n",
      "Epoch 57/70\n",
      "7200/7200 [==============================] - 189s 26ms/sample - loss: 0.5860 - acc: 0.7517 - val_loss: 0.5575 - val_acc: 0.7761\n",
      "Epoch 58/70\n",
      "7200/7200 [==============================] - 192s 27ms/sample - loss: 0.5837 - acc: 0.7571 - val_loss: 0.5575 - val_acc: 0.7761\n",
      "Epoch 59/70\n",
      "7200/7200 [==============================] - 184s 26ms/sample - loss: 0.5889 - acc: 0.7553 - val_loss: 0.5574 - val_acc: 0.7761\n",
      "Epoch 60/70\n",
      "7200/7200 [==============================] - 191s 27ms/sample - loss: 0.5816 - acc: 0.7661 - val_loss: 0.5614 - val_acc: 0.7722\n",
      "Epoch 61/70\n",
      "7200/7200 [==============================] - 192s 27ms/sample - loss: 0.5851 - acc: 0.7569 - val_loss: 0.5641 - val_acc: 0.7772\n",
      "Epoch 62/70\n",
      "7200/7200 [==============================] - 191s 27ms/sample - loss: 0.5805 - acc: 0.7582 - val_loss: 0.5567 - val_acc: 0.7750\n",
      "Epoch 63/70\n",
      "6112/7200 [========================>.....] - ETA: 27s - loss: 0.5839 - acc: 0.7590"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-bcd45b4ab79e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m70\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    485\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optimizers.Adam(decay=1e-4)\n",
    "main_input = Input(shape=(87,1), name='main_input')\n",
    "layer1 = Bidirectional(LSTM(87, return_sequences=True, name='layer1', recurrent_dropout=0.2))(main_input)\n",
    "layer2 = Dropout(0.4)(layer1)\n",
    "layer3 = Bidirectional(LSTM(43, return_sequences=False, name='layer2', recurrent_dropout=0.2))(layer2)\n",
    "layer4 = Dropout(0.4)(layer3)\n",
    "layer5 = Dense(100, activation='relu', name='layer3')(layer4)\n",
    "layer6 = Dropout(0.4)(layer5)\n",
    "rnn_output = Dense(3, activation='softmax', name='rnn_output')(layer6)\n",
    "\n",
    "model = Model(inputs=main_input, outputs=rnn_output)\n",
    "print('\\nCompiling model...')\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
    "model.summary()\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=70, validation_data=(X_test, y_test), shuffle=True, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000291C593B4C8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000291C593B4C8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000291C961CF78> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000291C961CF78> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000291BE53AE58> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000291BE53AE58> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000291C75D2EE8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000291C75D2EE8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000291D3FA0438> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000291D3FA0438> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000291CF410CA8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000291CF410CA8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000291D58AB288> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000291D58AB288> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000291CF0B0318> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000291CF0B0318> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000291C41FD828> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000291C41FD828> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000291D47EAA68> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000291D47EAA68> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000291C9B1BB88> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000291C9B1BB88> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000291C55D71F8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000291C55D71F8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000291D10924C8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000291D10924C8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000291D2A5AAF8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000291D2A5AAF8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000291C97F4D38> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000291C97F4D38> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n",
      "WARNING:tensorflow:Entity <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000291C60BA708> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n",
      "WARNING: Entity <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000291C60BA708> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000291D47EA948> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000291D47EA948> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'astor' has no attribute 'code_gen'\n",
      "INFO:tensorflow:Assets written to: LSTM.model\\assets\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file :\n",
    "\tjson_file.write(model_json)\n",
    "\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "model.save('LSTM.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This final code snippet was used by me to plot the model on the basis of history and figure out how well the model is training by looking at the graph of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-240db6ed668b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "plt.figure(1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss', 'accuracy', 'val_loss', 'val_acc'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
